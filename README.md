# MultiThreaded-WebCrawler

### Wikipedia Image Crawler Overview

The Wikipedia Image Crawler is designed to traverse websites, particularly Wikipedia, to extract and download PNG images. The program uses multi-threading to handle multiple URLs concurrently, utilizing queues and hash maps to manage the URLs to be visited and the PNG images found. It continues to traverse all embedded links on a page until it reaches the maximum specified number of PNG images. The program starts by defining macros and global variables to manage visited URLs, check for duplicate PNGs, and handle file pointers for logging. The `process_html` function parses HTML content to find links and adds them to the URL frontier queue, while the `process_png` function handles PNG images, checking for duplicates and saving valid PNG URLs. The `find_http` function extracts HTTP links from HTML content using XPath, validating URLs and adding them to the frontier and hash map. The `process_data` function determines the content type of the fetched data and calls the appropriate processing function (`process_html` or `process_png`). The `thread_function` is the worker thread that processes URLs from the frontier queue, fetching and processing data, and terminating when the desired number of PNG URLs is found or the queue is empty. In the main function, the program initializes hash maps, file pointers, and global variables, then parses command-line arguments to set the number of threads, the number of unique PNG URLs to find, and the log file. It fetches the initial URL and starts worker threads for concurrent URL processing, joining the threads and cleaning up resources upon completion. The crawler checks for duplicate URLs and PNGs using hash maps and maintains a log of visited URLs and found PNGs. Upon completion, it outputs the total execution time, demonstrating its efficiency. This crawler is particularly useful for extracting images from Wikipedia, leveraging its robust multi-threaded design to handle large-scale web scraping tasks efficiently.
